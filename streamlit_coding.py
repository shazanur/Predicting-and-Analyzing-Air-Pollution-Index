# -*- coding: utf-8 -*-
"""Streamlit coding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12XdcPZF47_TwqYkJkL6HLM3wZ6lcKfJ8
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import Lasso
import time

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression

# ==================================================
# PAGE CONFIG
# ==================================================
st.set_page_config(
    page_title="Malaysia Air Pollution Index Dashboard",
    page_icon="üå´Ô∏è",
    layout="wide"
)

# ==================================================
# CUSTOM CSS
# ==================================================
st.markdown("""
<style>
.big-title {
    font-size: 42px;
    font-weight: 700;
    color: #1f4e79;
    text-align: center;
}
.subtitle {
    font-size: 18px;
    text-align: center;
    color: #555;
}
.comment-box {
    background-color: #f4f6f9;
    padding: 12px;
    border-left: 5px solid #1f77b4;
    margin-top: 10px;
    font-size: 14px;
}
</style>
""", unsafe_allow_html=True)

st.markdown('<div class="big-title">üå´Ô∏è Air Pollution Index (API) Dashboard</div>', unsafe_allow_html=True)
st.markdown('<div class="subtitle">Exploration ‚Ä¢ Modelling ‚Ä¢ Evaluation ‚Ä¢ Prediction</div>', unsafe_allow_html=True)

st.divider()

# --------------------------------------------------
# LOAD DATA
# --------------------------------------------------
@st.cache_data
def load_data():
    return pd.read_csv("new_data.csv")

data = load_data()

# --------------------------------------------------
# PREPROCESSING & FEATURE ENGINEERING
# --------------------------------------------------
data = data.drop_duplicates()
data["air_pollution_concentration"] = data["air_pollution_concentration"].fillna(
    data["air_pollution_concentration"].median()
)

le = LabelEncoder()
data["air_pollutant_type"] = le.fit_transform(data["air_pollutant_type"])

limits = {
    "PM 2.5": 15,
    "PM 10": 45,
    "NO2": 0.02,
    "O3": 0.05,
    "CO": 4,
    "SO2": 0.02
}

pollutant_map = dict(zip(le.transform(le.classes_), le.classes_))

data["normalized_conc"] = data.apply(
    lambda row: row["air_pollution_concentration"] /
    limits[pollutant_map[row["air_pollutant_type"]]],
    axis=1
)

monthly_api = (
    data.groupby("month")["normalized_conc"]
    .mean()
    .reset_index()
    .rename(columns={"normalized_conc": "API_value"})
)

data = data.merge(monthly_api, on="month", how="left")

# Interaction features
data["traffic_emissions"] = data["car_registrations_y"] * data["normalized_conc"]
data["traffic_fire"] = data["car_registrations_y"] * data["fire_frp"]
data["ipi_pollution"] = data["ipi_index"] * data["normalized_conc"]
data["ipi_firefrp"] = data["ipi_index"] * data["fire_frp"]

features = [
    "avg_rainfall_mm",
    "fire_brightness",
    "fire_frp",
    "consumption",
    "normalized_conc",
    "traffic_emissions",
    "traffic_fire",
    "ipi_pollution",
    "ipi_firefrp"
]

X = data[features]
y = data["API_value"]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# ==================================================
# TRAIN MODELS (CACHED)
# ==================================================
@st.cache_resource
def train_models():
    models = {
        "Linear Regression": LinearRegression(),
        "Decision Tree": DecisionTreeRegressor(max_depth=10, random_state=42),
        "Random Forest": RandomForestRegressor(n_estimators=150, random_state=42),
        "Gradient Boosting": GradientBoostingRegressor(n_estimators=150, random_state=42)
    }

    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        pred = model.predict(X_test)

        results[name] = {
            "model": model,
            "MAE": mean_absolute_error(y_test, pred),
            "RMSE": np.sqrt(mean_squared_error(y_test, pred)),
            "R2": r2_score(y_test, pred)
        }
    return results

model_results = train_models()


# ==================================================
# SIDEBAR
# ==================================================
menu = st.sidebar.radio(
    "üìå Navigation",
    ["EDA", "Model Development", "Model Evaluation and Comparison", "Best Model & Prediction"]
)


# ==================================================
# EDA
# ==================================================
if menu == "EDA":
    st.subheader("üìä Exploratory Data Analysis")

    numeric_cols = data.select_dtypes(include=np.number).columns
    col = st.selectbox("Select feature", numeric_cols)

    fig, ax = plt.subplots()
    ax.hist(data[col], bins=30)
    ax.set_title(col)
    st.pyplot(fig)

    st.markdown("""
    <div class="comment-box">
    This distribution helps identify skewness, outliers, and overall variability 
    of the selected feature in the dataset.
    </div>
    """, unsafe_allow_html=True)

    st.dataframe(data[numeric_cols].describe())

# --------------------------------------------------
# MODEL DEVELOPMENT (WITH TUNING)
# --------------------------------------------------
if menu == "Model Development":
    st.subheader("‚öôÔ∏è Model Development & Hyperparameter Tuning")

    model_choice = st.selectbox(
        "Select Model",
        ["Decision Tree (Tuned)", "Random Forest", "Gradient Boosting", "Linear Regression (Tuned)"]
    )

    if model_choice == "Decision Tree (Tuned)":
        param_grid = {
            "max_depth": [None, 5, 10, 15],
            "min_samples_split": [2, 5, 10],
            "min_samples_leaf": [1, 2, 4]
        }

        grid = GridSearchCV(
            DecisionTreeRegressor(random_state=42),
            param_grid,
            cv=5,
            scoring="r2",
            n_jobs=-1
        )

        grid.fit(X_train, y_train)
        model = grid.best_estimator_
        st.write("Best Parameters:", grid.best_params_)
        y_pred = model.predict(X_test)

    elif model_choice == "Random Forest":
        model = RandomForestRegressor(n_estimators=200, random_state=42)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    elif model_choice == "Gradient Boosting":
        model = GradientBoostingRegressor(random_state=42)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    else:
        poly = PolynomialFeatures(degree=3)
        X_poly_train = poly.fit_transform(X_train)
        X_poly_test = poly.transform(X_test)

        grid = GridSearchCV(
            Lasso(max_iter=3000),
            {"alpha": [0.001, 0.01, 0.1, 1, 10]},
            cv=5,
            scoring="r2"
        )

        grid.fit(X_poly_train, y_train)
        model = grid.best_estimator_
        st.write("Best Alpha:", grid.best_params_["alpha"])
        y_pred = model.predict(X_poly_test)

    fig, ax = plt.subplots()
    ax.scatter(y_test, y_pred, alpha=0.6)
    ax.plot([y_test.min(), y_test.max()],
            [y_test.min(), y_test.max()], "r--")
    ax.set_xlabel("Actual")
    ax.set_ylabel("Predicted")
    ax.set_title("Actual vs Predicted")
    st.pyplot(fig)

    st.markdown("""
    <div class="comment-box">
    This plot compares actual vs predicted API values.\n
    Points sit exactly on the diagonal line --> Overfit\n
    Points closer to the diagonal line but have some spread --> Well-fit\n
    Points loosely scattered and dont follow the diagonal line --> Underfit\n
    </div>
    """, unsafe_allow_html=True)

# --------------------------------------------------
# MODEL EVALUATION AND COMPARISON
# --------------------------------------------------
if menu == "Model Evaluation and Comparison":
    st.subheader("üìà Model Evaluation and Comparison")

    st.caption("This section evaluates each model using multiple performance metrics and cross-validation.")

    models = {
        "Decision Tree": DecisionTreeRegressor(random_state=42),
        "Random Forest": RandomForestRegressor(n_estimators=200, random_state=42),
        "Gradient Boosting": GradientBoostingRegressor(random_state=42),
        "Linear Regression": LinearRegression()
    }

    results = []

    with st.spinner("‚è≥ Training and evaluating models..."):
        for name, model in models.items():
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring="r2")

            results.append({
                "Model": name,
                "MAE": mean_absolute_error(y_test, y_pred),
                "RMSE": np.sqrt(mean_squared_error(y_test, y_pred)),
                "R2": r2_score(y_test, y_pred),
                "CV R2 Mean": cv_scores.mean(),
                "CV R2 STD": cv_scores.std(),
                "Reliability and Stability": (
                    cv_scores.mean() / cv_scores.std()
                    if cv_scores.std() != 0 else np.nan
                )
            })

    results_df = pd.DataFrame(results)
    st.success("‚úÖ Model evaluation completed")
    num_cols = results_df.select_dtypes(include=[np.number]).columns
    st.dataframe(results_df.style.format("{:.4f}", subset=num_cols))
   
    # --------------------------------------------------
    # INTERACTIVE METRIC SELECTION
    # --------------------------------------------------
    metric = st.selectbox(
        "üìä Select metric for comparison",
        ["R2", "RMSE", "MAE", "Reliability and Stability"]
    )

    sort_order = st.radio(
        "Sort models by performance",
        ["Descending", "Ascending"],
        horizontal=True
    )

    ascending = sort_order == "Ascending"
    plot_df = results_df.sort_values(by=metric, ascending=ascending)

    # --------------------------------------------------
    # BAR CHART VISUALISATION
    # --------------------------------------------------
    fig, ax = plt.subplots()
    ax.bar(plot_df["Model"], plot_df[metric])
    ax.set_title(f"Model Comparison based on {metric}")
    ax.set_ylabel(metric)
    ax.set_xlabel("Model")

    for i, val in enumerate(plot_df[metric]):
        ax.text(i, val, f"{val:.3f}", ha="center", va="bottom")

    st.pyplot(fig)

    # --------------------------------------------------
    # COMMENTARY SECTION (AUTO-GENERATED)
    # --------------------------------------------------
    best_model = plot_df.iloc[-1] if ascending else plot_df.iloc[0]

    st.markdown(f"""
    <div class="comment-box">
    <b>Key Insight:</b><br>
    Based on <b>{metric}</b>, the best performing model is 
    <b>{best_model['Model']}</b> with a score of 
    <b>{best_model[metric]:.4f}</b>.
    <br><br>
    Models with higher <b>R¬≤</b> and lower <b>RMSE/MAE</b> indicate stronger predictive accuracy.
    Reliability and Stability highlights consistency across cross-validation folds.
    </div>
    """, unsafe_allow_html=True)

    # --------------------------------------------------
    # OPTIONAL ANIMATION (STREAMLIT SAFE)
    # --------------------------------------------------
    st.markdown("### üîÑ Model Performance Progress")
    progress_bar = st.progress(0)

    for i in range(100):
        progress_bar.progress(i + 1)
        time.sleep(0.005)


    
    
# --------------------------------------------------
# BEST MODEL & PREDICTION
# --------------------------------------------------
if menu == "Best Model & Prediction":
    st.subheader("‚úÖ Best Model: Gradient Boosting")

    st.markdown("""
    <div style="background-color:#eef3f8; padding:12px; border-left:5px solid #1f77b4;">
    Gradient Boosting is selected due to its strong predictive accuracy, ability to
    capture non-linear relationships, and stable generalisation performance.
    </div>
    """, unsafe_allow_html=True)

    gb_model = GradientBoostingRegressor(random_state=42)
    gb_model.fit(X_train, y_train)

    st.subheader("üîÆ Predict API Index")
    st.caption("Adjust environmental and socio-economic factors to estimate air quality conditions.")

   

# --------------------------------------------------
# INTERACTIVE INPUT LAYOUT
# --------------------------------------------------
# --------------------------------------------------
# INTERACTIVE INPUT LAYOUT (only shown when Best Model selected)
if menu == "Best Model & Prediction":
    col1, col2, col3 = st.columns(3)

    with col1:
        avg_rainfall = st.slider(
            "üåßÔ∏è Average Rainfall (mm)",
            float(data["avg_rainfall_mm"].min()),
            float(data["avg_rainfall_mm"].max()),
            float(data["avg_rainfall_mm"].mean()),
            help="Rainfall helps reduce particulate concentration in the air"
        )

        fire_brightness = st.slider(
            "üî• Fire Brightness",
            float(data["fire_brightness"].min()),
            float(data["fire_brightness"].max()),
            float(data["fire_brightness"].mean()),
            help="Indicates the intensity of detected fire hotspots"
        )

        fire_frp = st.slider(
            "üî• Fire Radiative Power",
            float(data["fire_frp"].min()),
            float(data["fire_frp"].max()),
            float(data["fire_frp"].mean()),
            help="Measures the energy released from biomass burning"
        )

    with col2:
        consumption = st.slider(
            "‚ö° Electricity Consumption",
            float(data["consumption"].min()),
            float(data["consumption"].max()),
            float(data["consumption"].mean()),
            help="Represents overall economic and industrial activity"
        )

        normalized_conc = st.slider(
            "ü´Å Normalised Pollution Concentration",
            float(data["normalized_conc"].min()),
            float(data["normalized_conc"].max()),
            float(data["normalized_conc"].mean()),
            help="Combined normalised concentration of major air pollutants"
        )

        traffic_emissions = st.slider(
            "üöó Traffic Emissions",
            float(data["traffic_emissions"].min()),
            float(data["traffic_emissions"].max()),
            float(data["traffic_emissions"].mean()),
            help="Vehicle-related pollution contribution"
        )

    with col3:
        traffic_fire = st.slider(
            "üö¶ Traffic √ó Fire Interaction",
            float(data["traffic_fire"].min()),
            float(data["traffic_fire"].max()),
            float(data["traffic_fire"].mean()),
            help="Interaction effect between traffic emissions and fire activity"
        )

        ipi_pollution = st.slider(
            "üè≠ IPI √ó Pollution",
            float(data["ipi_pollution"].min()),
            float(data["ipi_pollution"].max()),
            float(data["ipi_pollution"].mean()),
            help="Impact of industrial production on air quality"
        )

        ipi_firefrp = st.slider(
            "üèóÔ∏è IPI √ó Fire Radiative Power",
            float(data["ipi_firefrp"].min()),
            float(data["ipi_firefrp"].max()),
            float(data["ipi_firefrp"].mean()),
            help="Combined effect of industrial activity and fire intensity"
        )

    # --------------------------------------------------
    # PREPARE INPUT DATA
    # --------------------------------------------------
    input_df = pd.DataFrame([[
        avg_rainfall,
        fire_brightness,
        fire_frp,
        consumption,
        normalized_conc,
        traffic_emissions,
        traffic_fire,
        ipi_pollution,
        ipi_firefrp
    ]], columns=[
        "avg_rainfall_mm",
        "fire_brightness",
        "fire_frp",
        "consumption",
        "normalized_conc",
        "traffic_emissions",
        "traffic_fire",
        "ipi_pollution",
        "ipi_firefrp"
    ])

    input_scaled = scaler.transform(input_df)
    prediction = gb_model.predict(input_scaled)[0]

    # --------------------------------------------------
    # API STATUS INTERPRETATION
    # --------------------------------------------------
    if prediction <= 0.5:
        status = "üü¢ Good"
        colour = "#2ecc71"
        advice = "Air quality is satisfactory with minimal health risks."
    elif prediction <= 1.0:
        status = "üü° Moderate"
        colour = "#f1c40f"
        advice = "Acceptable air quality; sensitive groups should limit prolonged exposure."
    elif prediction <= 1.5:
        status = "üü† Unhealthy"
        colour = "#e67e22"
        advice = "Increased health risks for vulnerable populations."
    else:
        status = "üî¥ Hazardous"
        colour = "#e74c3c"
        advice = "Serious health effects expected; avoid outdoor activities."

    # --------------------------------------------------
    # DISPLAY RESULT
    # --------------------------------------------------
    st.markdown(f"""
    <div style="background-color:{colour}; padding:20px; border-radius:12px; color:white;">
        <h2>Predicted API Value: {prediction:.4f}</h2>
        <h3>Air Quality Status: {status}</h3>
        <p>{advice}</p>
    </div>
    """, unsafe_allow_html=True)
